---
layout: post
title:  "小样本学习文章阅读（MAML）"
date:   2020-07-13 14:35:19
categories: Reading
tags: ML

---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# 目录

* [目录](#目录)
* [MAML简介](#MAML简介)
* [在监督分类中的应用](#在监督分类中的应用)
* [训练过程](#训练过程)
* [参考文献](#参考文献)

# MAML简介

> The key idea underlying our method is to train the model’s initial parameters such that the model has maximal performance on a new task after the parameters have been up-dated through one or more gradient steps computed with a small amount of data from that new task.

本文的设想是**训练一组初始化参数**，通过在初始参数的基础上进行一或多步的梯度调整，来达到**仅用少量数据就能快速适应新task**的目的。为了达到这一目的，训练模型需要最大化新task的loss function的参数敏感度（*maximizing the sensitivity of the loss functions of new tasks with respect to the parameters*），当敏感度提高时，极小的参数（参数量）变化也可以对模型带来较大的改进。本文提出的算法可以适用于多个领域，包括少样本的回归、图像分类，以及增强学习，并且使用更少的参数量达到了当时（2017年）最先进的专注于少样本分类领域的网络的准确率。

核心算法示意图如下

![](..\assets\img\postsimg\20200713\3.jpg)

如上图所示，作者便将目标设定为，通过梯度迭代，找到对于task敏感的参数 θ 。训练完成后的模型具有对新task的学习域分布最敏感的参数，因此可以在仅一或多次的梯度迭代中获得最符合新任务的 θ* ，达到较高的准确率。

从另一个角度来看

![](..\assets\img\postsimg\20200713\4.jpg)

MAML由于采用了二阶导数来更新参数，因此示意图中经过两次折线确定参数的更新方向。相比右边的模型预训练方法，它是将参数根据每次的训练任务一阶导数的方向来更新参数。

# 在监督分类中的应用

假设这样一个监督分类场景，目的是训练一个数学模型 $M_{fine-tune} $ ，对未知标签的图片做分类，则两大步骤如下：

1. 利用 $C_1 \sim C_{10} $ 的数据集训练元模型 $M_{meta} $ 
2. 在 $P_1 \sim P_5$ 的数据集上精调（fine-tune）得到最终的模型 $M_{fine-tune} $ 。

MAML在监督分类中的算法伪代码如下：

![](..\assets\img\postsimg\20200713\6.jpg)

下面进行详细分析。该算法是 meta-train 阶段，目的是得到 $M_{meta} $；

**第一个Require**，反复随机抽取 $ \mathcal T$，得到一批（e.g. 1000个）task池，作为训练集 $ p(\mathcal T)$。

假设一个 $ \mathcal T$ 包含5类，每类20个样本，随机选5样本训练集，剩余15样本测试集。

> 训练样本就这么多，要组合形成那么多的task，岂不是不同task之间会存在样本的重复？或者某些task的query set会成为其他task的support set？没错！就是这样！我们要记住，MAML的目的，在于fast adaptation，即通过对大量task的学习，获得足够强的泛化能力，从而面对新的、从未见过的task时，通过fine-tune就可以快速拟合。task之间，只要存在一定的差异即可。

**第二个Require**，step size就是学习率，MAML是基于二重梯度（gradient by gradient），每次迭代有两次参数更新过程，所以有两个学习率可以调整。

**1**：随机初始化模型参数；

**2**：循环，对于每个epoch进行后续操作；

**3**：随机选取若干个（e.g. 4个） $ \mathcal T$  形成一个batch；

**步骤4**，对于每个batch中的每个 $ \mathcal T$ ，进行**第一次**梯度更新。可以理解对每个 $ \mathcal T$ 复制一个原模型计算出新的参数，用于第二轮梯度的计算；

​	**步骤5**，选取 $ \mathcal T$ 中的 **support set**（5way*5=25个样本），计算每个参数的梯度。作者在算法中写 with respect to K examples，默认对每一个类下的$K$个样本做计算。实际上参与计算的总计有$N\cdot K$个样本。这里的loss计算方法，在回归问题中，就是MSE；在分类问题中，就是cross-entropy；

​	**步骤6**，进行第一次梯度更新，GD

**步骤4~7**，完成第一次梯度更新。

**步骤8**，进行**第二次**梯度更新，此时计算出的梯度直接通过GD作用于原模型上，用于更新其参数。大致与步骤5相同，但是不同点有两处。

- 一处是不再分别利用每个 $ \mathcal T$ 的loss更新梯度，而是像常见的模型训练过程一样，计算一个 batch 的 loss 总和（使用第一次梯度更新后的参数），对梯度进行梯度下降GD。
- 另一处是这里参与计算的样本，是task中的**query set**（5way*15=75个样本），目的是增强模型在task上的泛化能力，避免过拟合support set。

步骤8结束后，模型结束在该batch中的训练，回到步骤3，继续采样下一个batch。

**总结**：MAML使用训练集优化内层循环，使用测试集优化模型，也就是外层循环

# 参考文献

<span id="ref1">[1]</span>  [Rust-in](https://www.zhihu.com/people/rustinnnnn). [MAML 论文及代码阅读笔记](https://zhuanlan.zhihu.com/p/66926599).